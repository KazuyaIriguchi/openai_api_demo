{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# チャットモデルで関数を呼び出す方法\n",
    "このノートでは、GPTモデルの機能を拡張するために、チャット補完APIを外部関数と組み合わせて使用する方法について説明します。\n",
    "\n",
    "functionsはチャット補完APIのオプションパラメータで、関数の仕様を提供するために使用することができます。この目的は、モデルが提供された仕様に準拠した関数引数を生成することを可能にすることです。なお、APIは実際に関数の呼び出しを実行することはありません。モデルの出力を使って関数呼び出しを実行するのは、開発者次第です。\n",
    "\n",
    "functionsパラメータが提供されている場合、デフォルトでは、モデルは関数のいずれかを使用することが適切である場合に決定します。APIは、function_callパラメータを{\"name\"}に設定することで、特定の関数を使用するように強制することができます： \"<insert-function-name>\"}とすることで、特定の関数の使用を強制することができる。また、function_callパラメータを \"none \"に設定することで、どの関数も使用しないように強制することも可能である。関数が使用された場合、出力には \"finish_reason \"が含まれます： 「また、関数の名前と生成された関数の引数を持つfunction_callオブジェクトが出力されます。\n",
    "\n",
    "概要\n",
    "このノートには、次の2つのセクションがあります：\n",
    "\n",
    "関数の引数を生成する方法： 関数の引数を生成する方法：関数のセットを指定し、APIを使用して関数の引数を生成します。\n",
    "モデル生成された引数で関数を呼び出す方法： モデル生成された引数を持つ関数を実際に実行することで、ループを閉じます。\n",
    "\n",
    "www.DeepL.com/Translator（無料版）で翻訳しました。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 関数の引数を生成する方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\ijiwa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.10.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in c:\\users\\ijiwa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scipy) (1.24.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tenacity\n",
      "  Using cached tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: tenacity\n",
      "Successfully installed tenacity-8.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktokenNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached tiktoken-0.4.0-cp310-cp310-win_amd64.whl (635 kB)\n",
      "Collecting requests>=2.26.0\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Collecting regex>=2022.1.18\n",
      "  Using cached regex-2023.6.3-cp310-cp310-win_amd64.whl (268 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached urllib3-2.0.3-py3-none-any.whl (123 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.1.0-cp310-cp310-win_amd64.whl (97 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2023.5.7-py3-none-any.whl (156 kB)\n",
      "Installing collected packages: urllib3, regex, idna, charset-normalizer, certifi, requests, tiktoken\n",
      "Successfully installed certifi-2023.5.7 charset-normalizer-3.1.0 idna-3.4 regex-2023.6.3 requests-2.31.0 tiktoken-0.4.0 urllib3-2.0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting termcolor\n",
      "  Using cached termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Installing collected packages: termcolor\n",
      "Successfully installed termcolor-2.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Using cached openai-0.27.8-py3-none-any.whl (73 kB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Collecting aiohttp\n",
      "  Using cached aiohttp-3.8.4-cp310-cp310-win_amd64.whl (319 kB)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\ijiwa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ijiwa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.20->openai) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ijiwa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ijiwa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.20->openai) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ijiwa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.20->openai) (2.0.3)\n",
      "Collecting attrs>=17.3.0\n",
      "  Using cached attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.9.2-cp310-cp310-win_amd64.whl (61 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.4-cp310-cp310-win_amd64.whl (28 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.3.3-cp310-cp310-win_amd64.whl (33 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\ijiwa\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->openai) (0.4.6)\n",
      "Installing collected packages: tqdm, multidict, frozenlist, attrs, async-timeout, yarl, aiosignal, aiohttp, openai\n",
      "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 attrs-23.1.0 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.8 tqdm-4.65.0 yarl-1.9.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\ijiwa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ijiwa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ijiwa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (2.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ijiwa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ijiwa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (3.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install scipy\n",
    "%pip install tenacity\n",
    "%pip install tiktoken\n",
    "%pip install termcolor\n",
    "%pip install openai\n",
    "%pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "import requests\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from termcolor import colored\n",
    "\n",
    "GPT_MODEL = \"gpt-4-0613\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ユーティリティ\n",
    "まず、Chat Completions APIを呼び出したり、会話の状態を維持・管理するためのユーティリティをいくつか定義しておきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=40), stop=stop_after_attempt(3))\n",
    "def chat_completion_request(messages, functions=None, function_call=None, model=GPT_MODEL):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer \" + openai.api_key,\n",
    "    }\n",
    "    json_data = {\"model\": model, \"messages\": messages}\n",
    "    if functions is not None:\n",
    "        json_data.update({\"functions\": functions})\n",
    "    if function_call is not None:\n",
    "        json_data.update({\"function_call\": function_call})\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"https://api.openai.com/v1/chat/completions\",\n",
    "            headers=headers,\n",
    "            json=json_data,\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(\"Unable to generate ChatCompletion response\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_conversation(messages):\n",
    "    role_to_color = {\n",
    "        \"system\": \"red\",\n",
    "        \"user\": \"green\",\n",
    "        \"assistant\": \"blue\",\n",
    "        \"function\": \"magenta\",\n",
    "    }\n",
    "    formatted_messages = []\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"system\":\n",
    "            formatted_messages.append(f\"system: {message['content']}\\n\")\n",
    "        elif message[\"role\"] == \"user\":\n",
    "            formatted_messages.append(f\"user: {message['content']}\\n\")\n",
    "        elif message[\"role\"] == \"assistant\" and message.get(\"function_call\"):\n",
    "            formatted_messages.append(f\"assistant: {message['function_call']}\\n\")\n",
    "        elif message[\"role\"] == \"assistant\" and not message.get(\"function_call\"):\n",
    "            formatted_messages.append(f\"assistant: {message['content']}\\n\")\n",
    "        elif message[\"role\"] == \"function\":\n",
    "            formatted_messages.append(f\"function: ({message['name']}): {message['content']}\\n\")\n",
    "    for formatted_message in formatted_messages:\n",
    "        print(\n",
    "            colored(\n",
    "                formatted_message,\n",
    "                role_to_color[messages[formatted_messages.index(formatted_message)][\"role\"]]\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本コンセプト\n",
    "仮想的な気象APIとのインターフェイスとして、いくつかの関数仕様を作成しましょう。これらの関数仕様をチャット補完APIに渡すことで、仕様に沿った関数引数を生成するようにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"format\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"location\", \"format\"],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"get_n_day_weather_forecast\",\n",
    "        \"description\": \"Get an N-day weather forecast\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"format\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                },\n",
    "                \"num_days\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"The number of days to forecast\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"location\", \"format\", \"num_days\"]\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在の天気についてモデルを促すと、明確な質問で応えてくれる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': 'ごめんなさい、あなたの現在の位置情報が必要です。どの都市の天気を知りたいですか？また、温度は摂氏（celsius）と華氏（fahrenheit）のどちらで表示しますか？'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"関数に差し込む値について、勝手に決めつけないでください。ユーザーからの要求があいまいな場合は、説明を求めること\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"今日の天気は？\"})\n",
    "chat_response = chat_completion_request(\n",
    "    messages, functions=functions\n",
    ")\n",
    "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
    "messages.append(assistant_message)\n",
    "assistant_message"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不足する情報を提供すると、適切な関数引数を生成してくれます。\n",
    "\n",
    "（gpt-3.5-turbo-0613を使って日本語の場合、勝手にパラメータを生成してしまうかも）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': None,\n",
       " 'function_call': {'name': 'get_current_weather',\n",
       "  'arguments': '{\\n  \"location\": \"愛知県\",\\n  \"format\": \"celsius\"\\n}'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.append({\"role\": \"user\", \"content\": \"日本の愛知県にいます。\"})\n",
    "chat_response = chat_completion_request(\n",
    "    messages, functions=functions\n",
    ")\n",
    "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
    "messages.append(assistant_message)\n",
    "assistant_message"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "別の方法で促すことで、伝えた別の機能をターゲットにさせることができるのです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': '確認させて頂きますが、n日間の詳細な予報をお求めですか？また、摂氏(Celsius)か華氏(Fahrenheit)で気温をお求めですか？'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"関数に与える引数を勝手に決めつけないでください。ユーザーからの要求があいまいな場合は、説明を求めること。\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"今後n日間の日本の愛知県の天気はどうなるのでしょうか？\"})\n",
    "chat_response = chat_completion_request(\n",
    "    messages, functions=functions\n",
    ")\n",
    "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
    "messages.append(assistant_message)\n",
    "assistant_message\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "もう一度言いますが、モデルはまだ十分な情報を持っていないため、我々に説明を求めているのです。この場合、予測する場所はすでに分かっていますが、予測に必要な日数は何日か知る必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': 0,\n",
       " 'message': {'role': 'assistant',\n",
       "  'content': None,\n",
       "  'function_call': {'name': 'get_n_day_weather_forecast',\n",
       "   'arguments': '{\\n  \"location\": \"愛知県\",\\n  \"format\": \"celsius\",\\n  \"num_days\": 5\\n}'}},\n",
       " 'finish_reason': 'function_call'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.append({\"role\": \"user\", \"content\": \"5日間\"})\n",
    "chat_response = chat_completion_request(\n",
    "    messages, functions=functions\n",
    ")\n",
    "chat_response.json()[\"choices\"][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特定の関数を強制的に使用させる、または関数を使用させない\n",
    "function_call引数を使うことで、特定の関数、例えばget_n_day_weather_forecastを使うようモデルに強制することができます。そうすることで、その関数の使い方をモデルに強制的に推測させることができます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': None,\n",
       " 'function_call': {'name': 'get_n_day_weather_forecast',\n",
       "  'arguments': '{\\n  \"location\": \"Toronto, Canada\",\\n  \"format\": \"celsius\",\\n  \"num_days\": 5\\n}'}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# このセルでは、モデルに get_n_day_weather_forecast を使わせています\n",
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"関数に与える引数を勝手に決めつけないでください。ユーザーからの要求があいまいな場合は、説明を求めること。\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"カナダのトロントの天気予報をお願いします。\"})\n",
    "chat_response = chat_completion_request(\n",
    "    messages, functions=functions, function_call={\"name\": \"get_n_day_weather_forecast\"}\n",
    ")\n",
    "chat_response.json()[\"choices\"][0][\"message\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': None,\n",
       " 'function_call': {'name': 'get_n_day_weather_forecast',\n",
       "  'arguments': '{\\n  \"location\": \"Toronto, Canada\",\\n  \"format\": \"celsius\",\\n  \"num_days\": 5\\n}'}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_n_day_weather_forecast を使うようにモデルに強制しなければ、そうならないかもしれません\n",
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"関数に与える引数を勝手に決めつけないでください。ユーザーからの要求があいまいな場合は、説明を求めること。\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"カナダのトロントの天気予報をお願いします。\"})\n",
    "chat_response = chat_completion_request(\n",
    "    messages, functions=functions\n",
    ")\n",
    "chat_response.json()[\"choices\"][0][\"message\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、モデルに関数を全く使わせないようにすることもできます。そうすることで、適切な関数呼び出しが行われないようにすることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': 'カナダのトロントの現在の天気（摂氏）を取得するために、天気APIを使用します。しばらくお待ちください。'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"関数に与える引数を勝手に決めつけないでください。ユーザーからの要求があいまいな場合は、説明を求めること。\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"カナダのトロントの現在の天気（摂氏）を教えてください。\"})\n",
    "chat_response = chat_completion_request(\n",
    "    messages, functions=functions, function_call=\"none\"\n",
    ")\n",
    "chat_response.json()[\"choices\"][0][\"message\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデルで生成された引数で関数を呼び出す方法\n",
    "次の例では、入力がモデルで生成された関数を実行する方法を示し、これを使用してデータベースに関する質問に答えるエージェントを実装します。簡単のために、Chinookサンプルデータベースを使用します。\n",
    "\n",
    "注意：モデルは正しいSQLを生成することに完璧に信頼できるわけではないので、本番環境ではSQLの生成はハイリスクである可能性があります。\n",
    "\n",
    "## SQLクエリを実行する関数を指定する\n",
    "まず、SQLiteデータベースからデータを抽出するための有用なユーティリティ関数を定義しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened database successfully\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"data/Chinook.db\")\n",
    "print(\"Opened database successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_names(conn):\n",
    "    \"\"\"テーブル名のリストを返す\"\"\"\n",
    "    table_names = []\n",
    "    tables = conn.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    for table in tables.fetchall():\n",
    "        table_names.append(table[0])\n",
    "    return table_names\n",
    "\n",
    "def get_column_names(conn, table_name):\n",
    "    \"\"\"コラム名のリストを返す\"\"\"\n",
    "    column_names = []\n",
    "    columns = conn.execute(f\"PRAGMA table_info('{table_name}');\").fetchall()\n",
    "    for col in columns:\n",
    "        column_names.append(col[1])\n",
    "    return column_names\n",
    "\n",
    "def get_database_info(conn):\n",
    "    \"\"\"データベース内の各テーブルのテーブル名とカラムを含むdict型のリストを返す\"\"\"\n",
    "    table_dicts = []\n",
    "    for table_name in get_table_names(conn):\n",
    "        column_names = get_column_names(conn, table_name)\n",
    "        table_dicts.append({\"table_name\": table_name, \"column_names\": column_names})\n",
    "    return table_dicts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これらのユーティリティ関数を使用して、データベーススキーマの表現を抽出することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_schema_dict = get_database_info(conn)\n",
    "database_schema_string = \"\\n\".join(\n",
    "    [\n",
    "        f\"Table: {table['table_name']}\\nColumns: {'.'.join(table['column_names'])}\"\n",
    "        for table in database_schema_dict\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前回と同様に、APIに引数を生成させたい関数の関数仕様を定義します。データベーススキーマを関数仕様に挿入していることに注目してください。これは、モデルにとって重要なことです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"ask_database\",\n",
    "        \"description\": \"Use this function to answer user questions about music. Output should be a fully formed SQL query.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": f\"\"\"\n",
    "                            SQL query extracting info to answer the user's question.\n",
    "                            SQL should be written using this database schema:\n",
    "                            {database_schema_string}\n",
    "                            The query should be returned in plain text, not in JSON.\n",
    "                            \"\"\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"query\"],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQLクエリの実行\n",
    "では、実際にデータベースに対してクエリを実行する関数を実装してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_database(conn, query):\n",
    "    \"\"\"指定されたSQLクエリでSQLiteデータベースに問い合わせる関数\"\"\"\n",
    "    try:\n",
    "        results = str(conn.execute(query).fetchall())\n",
    "    except Exception as e:\n",
    "        results = f\"query failed with error: {e}\"\n",
    "    return results\n",
    "\n",
    "def execute_function_call(message):\n",
    "    if message[\"function_call\"][\"name\"] == \"ask_database\":\n",
    "        query = eval(message[\"function_call\"][\"arguments\"])[\"query\"]\n",
    "        results = ask_database(conn, query)\n",
    "    else:\n",
    "        results = f\"Error: function {message['function_call']['name']} does not exist\"\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msystem: Chinook音楽データベースに対するSQLクエリを生成して、ユーザーの質問に答えてください。\n",
      "\u001b[0m\n",
      "\u001b[32muser: こんにちは。トラック数でトップ5のアーティストは誰ですか？\n",
      "\u001b[0m\n",
      "\u001b[34massistant: {'name': 'ask_database', 'arguments': '{\\n  \"query\": \"SELECT artists.Name, COUNT(tracks.TrackId) as TrackCount FROM artists JOIN albums ON artists.ArtistId = albums.ArtistId JOIN tracks ON albums.AlbumId = tracks.AlbumId GROUP BY artists.ArtistId ORDER BY TrackCount DESC LIMIT 5;\"\\n}'}\n",
      "\u001b[0m\n",
      "\u001b[35mfunction: (ask_database): [('Iron Maiden', 213), ('U2', 135), ('Led Zeppelin', 114), ('Metallica', 112), ('Deep Purple', 92)]\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"Chinook音楽データベースに対するSQLクエリを生成して、ユーザーの質問に答えてください。\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"こんにちは。トラック数でトップ5のアーティストは誰ですか？\"})\n",
    "chat_response = chat_completion_request(messages, functions)\n",
    "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
    "messages.append(assistant_message)\n",
    "if assistant_message.get(\"function_call\"):\n",
    "    results = execute_function_call(assistant_message)\n",
    "    messages.append({\"role\": \"function\", \"name\": assistant_message[\"function_call\"][\"name\"], \"content\": results})\n",
    "pretty_print_conversation(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msystem: Chinook音楽データベースに対するSQLクエリを生成して、ユーザーの質問に答えてください。\n",
      "\u001b[0m\n",
      "\u001b[32muser: こんにちは。トラック数でトップ5のアーティストは誰ですか？\n",
      "\u001b[0m\n",
      "\u001b[34massistant: {'name': 'ask_database', 'arguments': '{\\n  \"query\": \"SELECT artists.Name, COUNT(tracks.TrackId) as TrackCount FROM artists JOIN albums ON artists.ArtistId = albums.ArtistId JOIN tracks ON albums.AlbumId = tracks.AlbumId GROUP BY artists.ArtistId ORDER BY TrackCount DESC LIMIT 5;\"\\n}'}\n",
      "\u001b[0m\n",
      "\u001b[35mfunction: (ask_database): [('Iron Maiden', 213), ('U2', 135), ('Led Zeppelin', 114), ('Metallica', 112), ('Deep Purple', 92)]\n",
      "\u001b[0m\n",
      "\u001b[32muser: 最も曲数の多いアルバム名はなんですか？\n",
      "\u001b[0m\n",
      "\u001b[34massistant: {'name': 'ask_database', 'arguments': '{\\n  \"query\": \"SELECT albums.Title, COUNT(tracks.TrackId) AS TrackCount FROM albums JOIN tracks ON albums.AlbumId = tracks.AlbumId GROUP BY albums.AlbumId ORDER BY TrackCount DESC LIMIT 1;\"\\n}'}\n",
      "\u001b[0m\n",
      "\u001b[35mfunction: (ask_database): [('Greatest Hits', 57)]\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "messages.append({\"role\": \"user\", \"content\": \"最も曲数の多いアルバム名はなんですか？\"})\n",
    "chat_response = chat_completion_request(messages, functions)\n",
    "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
    "messages.append(assistant_message)\n",
    "if assistant_message.get(\"function_call\"):\n",
    "    results = execute_function_call(assistant_message)\n",
    "    messages.append({\"role\": \"function\", \"name\": assistant_message[\"function_call\"][\"name\"], \"content\": results})\n",
    "pretty_print_conversation(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
