{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 複数の関数パラメータを取得し、実行するデモ\n",
    "\n",
    "簡単なフロー：\n",
    "\n",
    "1. タスクを指示する（例：テーブルを経由してキッチンに移動して）\n",
    "2. ChatCompletion実行\n",
    "3. 応答の `finish_reason` が `function_call` の場合、パラメータを保持して再度そのままChatCompletionを実行する\n",
    "4. 応答の `finish_reason` が `stop` になったら、保持したパラメータをもとに関数を実行し、ユーザーに制御を渡す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
      "     ---------------------------------------- 73.6/73.6 kB 4.0 MB/s eta 0:00:00\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Collecting aiohttp\n",
      "  Using cached aiohttp-3.8.4-cp310-cp310-win_amd64.whl (319 kB)\n",
      "Collecting requests>=2.20\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached urllib3-2.0.3-py3-none-any.whl (123 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.2.0-cp310-cp310-win_amd64.whl (96 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2023.5.7-py3-none-any.whl (156 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting attrs>=17.3.0\n",
      "  Using cached attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.9.2-cp310-cp310-win_amd64.whl (61 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.3.3-cp310-cp310-win_amd64.whl (33 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.4-cp310-cp310-win_amd64.whl (28 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: colorama in .\\.venv\\lib\\site-packages (from tqdm->openai) (0.4.6)\n",
      "Installing collected packages: urllib3, tqdm, multidict, idna, frozenlist, charset-normalizer, certifi, attrs, async-timeout, yarl, requests, aiosignal, aiohttp, openai\n",
      "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 attrs-23.1.0 certifi-2023.5.7 charset-normalizer-3.2.0 frozenlist-1.3.3 idna-3.4 multidict-6.0.4 openai-0.27.8 requests-2.31.0 tqdm-4.65.0 urllib3-2.0.3 yarl-1.9.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tenacity\n",
      "  Using cached tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: tenacity\n",
      "Successfully installed tenacity-8.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install openai\n",
    "%pip install tenacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "\n",
    "GPT_MODEL = \"gpt-4-0613\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_to_object(name: str):\n",
    "    print(\"move to object: \" + name)\n",
    "\n",
    "def set_speed(speed: float):\n",
    "    print(\"set_speed: \" + speed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatCompletionの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=40), stop=stop_after_attempt(3))\n",
    "def chat_completion_request(\n",
    "    messages: dict,\n",
    "    functions: list = None,\n",
    "    function_call: dict = None,\n",
    "    model: str = GPT_MODEL\n",
    "):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer \" + openai.api_key,\n",
    "    }\n",
    "    json_data = {\"model\": model, \"messages\": messages}\n",
    "    if functions is not None:\n",
    "        json_data.update({\"functions\": functions})\n",
    "    if function_call is not None:\n",
    "        json_data.update({\"function_call\": function_call})\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"https://api.openai.com/v1/chat/completions\",\n",
    "            headers=headers,\n",
    "            json=json_data,\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(\"Unable to generate ChatCompletion response\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 関数実行処理の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_function_call(assistant_message: dict):\n",
    "    try:\n",
    "        parsed_output = json.loads(\n",
    "            assistant_message[\"function_call\"][\"arguments\"]\n",
    "        )\n",
    "        arguments = \", \".join(str(arg) for arg in parsed_output.values())\n",
    "        method = f\"{assistant_message['function_call']['name']}('{arguments}')\"\n",
    "        eval(method)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functionsの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"move_to_object\",\n",
    "        \"description\": \"Move to target position\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"name\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"target object name\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"name\"]\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"set_speed\",\n",
    "        \"description\": \"Set move speed\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"speed\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"The number of speed\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"speed\"]\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## システムメッセージと最初のユーザーメッセージ\n",
    "\n",
    "「テーブルを経由してキッチンに移動して」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': 'To make sure I understand your instructions correctly, would you like me to:\\n\\n1. Move to the table first, then proceed to the kitchen?\\nor\\n2. Navigate directly to the kitchen, passing by the table?'}\n"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "messages.append(\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"\n",
    "    }\n",
    ")\n",
    "messages.append(\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Move to the kitchen via the table.\"\n",
    "    }\n",
    ")\n",
    "chat_response = chat_completion_request(\n",
    "    messages, functions=functions\n",
    ")\n",
    "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
    "messages.append(assistant_message)\n",
    "print(assistant_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "指示が曖昧だと、「テーブルに移動してからキッチンに移動するか、テーブルを取って直接キッチンに行くか、どちらですか？」と聞き返してくる\n",
    "\n",
    "「テーブルに移動してからキッチンに移動して」と指示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-7b2Ja4hy28bc2i9U1NgnXgZJO6NEY', 'object': 'chat.completion', 'created': 1689061390, 'model': 'gpt-4-0613', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': None, 'function_call': {'name': 'move_to_object', 'arguments': '{\\n  \"name\": \"table\"\\n}'}}, 'finish_reason': 'function_call'}], 'usage': {'prompt_tokens': 171, 'completion_tokens': 16, 'total_tokens': 187}}\n"
     ]
    }
   ],
   "source": [
    "messages.append(\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"First we move to the table and then proceed to the kitchen.\"\n",
    "    }\n",
    ")\n",
    "chat_response = chat_completion_request(\n",
    "    messages, functions=functions\n",
    ")\n",
    "print(chat_response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のようにパラメータを生成してくれた。\n",
    "\n",
    "`'function_call': {'name': 'move_to_object', 'arguments': '{\\n  \"name\": \"table\"\\n}'}}`\n",
    "\n",
    "キッチンへ移動してほしいので、この応答を`messages`にふくめてもう一度`ChatCompletion`を実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-7b2MmGW6T7gos6s0rHx3YfQzjJ9NZ', 'object': 'chat.completion', 'created': 1689061588, 'model': 'gpt-4-0613', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': None, 'function_call': {'name': 'move_to_object', 'arguments': '{\\n  \"name\": \"kitchen\"\\n}'}}, 'finish_reason': 'function_call'}], 'usage': {'prompt_tokens': 190, 'completion_tokens': 17, 'total_tokens': 207}}\n"
     ]
    }
   ],
   "source": [
    "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
    "messages.append(assistant_message)\n",
    "\n",
    "chat_response = chat_completion_request(\n",
    "    messages, functions=functions\n",
    ")\n",
    "print(chat_response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "キッチンへ移動するパラメータを生成してくれた。\n",
    "\n",
    "```\n",
    "'function_call': {'name': 'move_to_object', 'arguments': '{\\n  \"name\": \"kitchen\"\\n}'}}\n",
    "```\n",
    "\n",
    "この応答を含めて更に`ChatCompletion`を実行すると、応答メッセージを返してくれる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-7b2P0tyvxUKjRuplgC59DN4Wg5jRZ', 'object': 'chat.completion', 'created': 1689061726, 'model': 'gpt-4-0613', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'Alright, I have moved to the table first and then proceeded to the kitchen.'}, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 210, 'completion_tokens': 17, 'total_tokens': 227}}\n"
     ]
    }
   ],
   "source": [
    "# assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
    "# messages.append(assistant_message)\n",
    "\n",
    "chat_response = chat_completion_request(\n",
    "    messages, functions=functions\n",
    ")\n",
    "print(chat_response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "応答：\n",
    "\n",
    "```\n",
    "'content': 'Alright, I have moved to the table first and then proceeded to the kitchen.'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これらを対話的に実行できるようにしたスクリプトはこちら\n",
    "\n",
    "[multiple_function_calling_demo.py](./multiple_function_calling_demo.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
